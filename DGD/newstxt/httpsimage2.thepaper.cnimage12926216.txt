记忆哲学：解码人工智能及其发展的钥匙
杨庆峰、伍梦秋
2018-12-08 	16:36
在人工智能的发展过程中，众多相关学科中哲学的作用极易忽视，甚至被挤压到以“伦理问题”的名义存在的领域。尽管科学家与哲学家在后果论上达成了一致，双方以极大热情投入到人工智能伦理问题的研究中，并形成了二者交往的主导方式，但这对于哲学自身的发展来说依然不够。且不说哲学家与科学家共同联手探索人工智能的伦理问题中依然存在一些问题：如基本范畴存在分歧、对话需要继续深入。如果将人工智能时代哲学出场的方式仅仅定位为伦理路径，这未免过于狭窄了。幸运的是，我们也看到很多学者从不同视角拓展着哲学的路径，如机器智能的主体性、智能社会发展的挑战。本文试图对从记忆哲学角度阐述哲学对于人工智能发展提供的洞见：记忆哲学提供了一种思考AI的视野，即从记忆角度能够很好地理解和解释AI的发展的理论基础、存在的理论争论、未来的发展方向及其可能面临的危机。在进入分析之前，需要说明的是，记忆哲学提出的三个原则是：（1）记忆是时间意识及其意识现象得以产生的条件；（2）记忆哲学涵盖记忆与遗忘两个维度，缺一不可。（3）记忆与回忆存在着根本区分。而这三个原则将成为本文反思AI发展的重要原则。
目前关于AI发展过程中最为有名的争议是强AI与弱AI之争，在此基础上衍生了人工智能三阶段发展理论：弱人工智能、强人工智能和超人工智能。但是在这一观点中，将记忆放置到弱人工智能的阶段。在这种理解中，记忆被看做是信息的存储，与理智能力是并列形式之一。
上述争论能否称得上是范式之争存在着诸多争议，按照库恩的观点，一个范式必须符合:1)在一定时期内科学共同体普遍接受；2）为科学家提供据以工作的模型、范例。但是在人工智能领域，至少行为主义、联想主义和计算主义三大流派之间的内战硝烟始终弥漫着没有散去，难以实现统一，所以并没有公认的范式出现。然而它作为技术争论却没有任何问题，所以我们把它称之为“人工智能领域技术层面的强弱之争”。这一争论的实质是AI是否能够具有通用意识。从历史上看，这一争论的形成却与英国计算机科学家图灵和美国哲学家约翰·塞尔分不开。在图灵看来，一个机器如果能够通过人类测试，那么在一定程度上说这个机器就通过了图灵测试。此时，我们可以说这部通过图灵测试的机器就属于强AI。从图灵的观点看，目前大部分AI机器只是出于弱的阶段，能够被人识别仅仅是一部机器而已，甚至有时候称不上是弱，不值得人们为之花费太多的测试成本。2015年，一项研究成果显示出AI已经通过了“视觉图灵测试”。严格地说，“通过”是极其日常化或喜欢被媒体使用的用语，在科学界并不会使用。科学家只是关心更具体的任务实现。而在塞尔看来，一个机器只有具有心智，才是强AI。在二者的分歧中，基本上可以概括出任务实现和自主意识的区分。科学家强调前者，而哲学家则喜欢讨论更为普遍的自主意识问题。
围绕争论，基本上形成了两个明显的派别，一类是科学流派，即AI研究专家认为机器还只是停留在弱的阶段，因为AI机器所表现出的行为非常弱智，强AI机器还远未能到来；另一派是哲学流派，即人文学者和哲学家认为机器已然或者必然进入强的阶段，因为机器通过图灵测试已经成为现实，同时还因为机器心灵具有自身演化规律，通过奇点已经成为必然。这两个派别之间的争议极大。在科学流派看来，人文学者多是杞人忧天，甚至是像唐吉坷德一样，朝着AI风车冲击，有些妄想症；而在人文学者看来，科学家和工程师目光短浅，只盯住眼下，未能意识到AI发展的必然。
在强弱之争的问题上，人工智能三种流派作用各不相同，它们在解释意识本质及其产生的问题上存在差异。首先，对行为主义而言，自主意识不是必要的条件，甚至不需要意识存在假设。这种理论可以从两个方面做出解释，其一从机器内在原理看，主要源自控制论，其原理“为控制论及感知-动作型控制系统。”，这是指机器自身的行为而言；其二是从机器与环境的行为应对关系出发，强调机器对于环境的适应行为。如同心理学领域的行为主义，意识存在是无效的假设，在人工智能领域中，意识存在依然是无效假设。其次，对符号主义而言，自主意识就成为必要的条件。这种理论源自数理逻辑，其原理为物理符号系统(即符号操作系统)的连接和推理。这一背后需要意识的存在或者类人意识的存在，而这也不是假设；第三，对联结主义而言，同样需要自主意识作为必要条件。这种理论源自仿生学，主要原理为模仿人类神经网络及神经网络间的连接机制与学习算法。它们以某种方式为机器心灵的可能性提供了论证。
这三种立场都存在问题。行为主义强调对环境做出反应，所以最终不会产生强的人工智能的担忧，因为最多是对环境做出的更为人化反应。符号主义和联结主义所存在的问题是陷入到实体主义的立场之中。实体主义探讨某类特定的主体实体具有意识，对于AI而言，AI成为一个有自身基础意识的主体，基础意识的运行机制与人类似或者以自身的独特逻辑进行。而这条路径经常会碰到一个无法绕开的悖论：因为意识是人类特定的规定性，而非人的存在物从实体意义上拥有意识就成为一个无法论证的课题。实体主义的立场将会遭遇来自心灵主义的严厉指责。在心灵主义看来，以意向性为特征的只能属于心灵现象，而作为各种材料组合而成的AI是不可能具备这种意识的。
某种意义上，实体主义将强弱之争引入到了一个死胡同。面对这种死胡同，记忆哲学的出场显得非常必要。本文认为，记忆哲学将成为一个可能的出路，它从意识产生过程而不是主体角度对人工智能的意识问题做出解释。在本文所说记忆哲学中，为了破解强弱之争陷入的死胡同，我们需要摆脱将记忆看作是信息过程的神经科学的观点，也需要摆脱将记忆看做是心理联想或者精神性时间旅行的心理学观点，而是将记忆看作是时间意识、意识现象及其自主意识产生以及理解智能存在体的历史条件。在哲学史上，多位哲学家的观点支持了这一点。德国的黑格尔、布伦塔诺和伽达默尔等共同奠定了这一理论的基础。
在黑格尔那里，记忆的地位被极大忽略，甚至隐藏在“意识的直接性”底下无法见到天日。从黑格尔的问题自我意识的生成出发，循着他的解决过程会发现一个有趣的现象：记忆之光在精神的运作中隐隐发光。他指出“个体不再需要把具体存在转化为自在存在的形式，而仅只需要把已经呈现于记忆中的自在存在转化为自为存在的形式。”在这个观点的表述中，“在记忆之中”是精神发生的一个形式结构。因此，可以说黑格尔对记忆的解读是不同于以往的哲学家，记忆是自在存在之所，自在存在从这里出发转为自为存在。可惜的是，这个观点被极大地忽略了。与黑格尔不同，布伦塔诺更多从哲学心理学的角度将记忆看作是观念的一联结的前提条件。在他看来，记忆是过去的心理现象成为对象的条件。第三位哲学家是伽达默尔，他的解释学体系对于记忆的定位就是理解人自身存在的历史条件形式。在汉斯·卢恩（Hans Ruin）看来，《真理与方法》不像表面上看起来那样与记忆无关，而是有着深刻的关联。他指出，伽达默尔所做的事情，是将记忆的理解从心理能力解放出来，而从人的有限的、历史存在的基本要素的角度来看待。在他看来，伽达默尔是从历史的、解释学的理解中来思考记忆的。所以，汉斯的工作主要揭示出两点值得我们关注：1）记忆不是心理能力（联想或者表征能力）；2）记忆不是记忆术（保留信息的技巧），而是人的有限的、历史存在的前提条件。
让我们再回到AI的强弱之争中，机器是否具有自我意识？的问题上。如果仅仅将记忆看做是AI进行学习将所获得的信息被编码、存储，并且转化认知的过程，那么这个问题永远无法解决。如果把记忆看作是机器个体意识产生的前提条件，那么，就可以看到一种可能性的存在。对于AI而言，必要的前提具备了，信息感知、记忆，但是缺乏其他条件还不足以产生出基础意识。我们需要解释的是自主意识产生过程中的那个飞跃：所以，如果记忆是意识出现的场域和条件，意识的发生也就是将存在于记忆之中的存在显现出来。强人工智能的出现并不是没有可能，而基于因果关系的意识发生理论就无法解释这种飞跃。
事实上，记忆已经成为制约AI发展的重要因素，是AI进行学习、决策以及合理行动的基础。那么与哪些记忆有着密切的关系呢？AI发展与心理学领域中的记忆分类有着不可分割的关系。20世纪70年代，心理学家为记忆分类划定了一个稳定的框架。1970年美国心理学家缪勒（George A·Miller）提出“短时记忆”的概念，但是他所提出的这个概念只是一个理论推测，缺乏足够的证据；80年代，加拿大心理学家图尔文（Endel Tulving）将记忆区分为语义记忆、情景记忆和程序记忆；1974年英国心理学家艾伦·巴德利（Alan Baddeley）在提出“工作记忆”（working memory）的替代性概念，是指对信息进行短暂加工和存储的能量有限的记忆系统。这一阶段确立的分类框架也被神经科学家接受。2004年宫下雅秀（Yasushi Miyashita）在一篇题为《认知记忆：分子和网络机器以及它们自上向下的控制》接受了这种讲法。“长期记忆被分为外显记忆（陈述）和内隐记忆（非陈述）。内隐记忆无需觉知而影响行为，外显记忆则进一步被划分为语义记忆（表示关于世界的一般知识）和情景记忆（表征一个人过去的知识）。这种形式直接运用于人类记忆系统。相似的谱系也可以用于动物记忆，尽管缺乏一些人类记忆的显著特征。因此，诸如类语义或者类情景记忆用来指动物记忆系统。”这一分类框架可以作为我们分析这一问题的出发点。
（1）记忆模块增强了神经网络。一般说来，传统神经网络只能做到孤立记忆，无法做到连续记忆，为了克服这一缺陷，科学家提出了循环神经网络（RNN），但是缺陷是不能进行长期记忆。为了解决这个问题，人工智能学者提出了不同的记忆模式构成的模块。1997年森普·霍克赖特（Sepp Hochreiter）提出长短期记忆（LSTM），解决了上述神经网络存在的连续性和长期性记忆问题；2014年维森特（Weston，J）等人提出记忆网络（Memory Networks），即联合存储器，在此基础上发展出许多其他相关模式，如Nested LSTM。这些模式的提出在一定程度上解决了长期记忆的问题。如DeepMind开发了一款可微神经计算机（DNC）的机器学习模型，就是利用了可以读写的外部记忆神经网络，极大扩展了神经网络在表征变量和数据结构以及长时间存储数据的能力。同年，他们利用记忆模块解决了一次性学习（one-shot learning）的问题。
（2）长短期记忆成为AI内部机制、算法的必要模块。霍克赖特和施米特胡贝（Jürgen Schmidhuber）等人将记忆因素考虑在内解决AI的问题并提出了长短期记忆网络（LSTM）的概念这一思路获得了广泛认可。2013年格莱威（Graves）等人运用这一模式解决语言识别（speech recognition）问题；2014年艾莉亚·斯特斯凯威（Ilya Sutskever）等人运用这一模式解决机器翻译（machine translation）的问题；奥利奥·维尼亚斯（ Oriol Vinyals）等人运用这一模式解决了图像到文字转换的问题。]2015年加拿大学者朱小丹（Xiaodan Zhu）提出了S-LSTM模式用于语言或图像解析结构（image parse structures）；2016年卡莱克贝纳（Kalchbrenner）提出G-LSTM[Grid-LSTM]模式运用于属性预测（character prediction）、机器翻译（machine translation ）和图像分类（and image classification）。从这些文章可以看出，AI非常依赖的一个记忆分类是心理学中的长短期记忆。此外，在AI算法上，以记忆为核心的算法起到了比较重要的作用，如循环神经网络（RNN）中的长短期记忆神经网络（LSTM），但是这种算法始终为认知和推理起铺垫作用的。其功能是“使用传统的通过时间的反向传播（BPTT）或实时循环学习（RTTL），在时间中反向流动的误差信号往往会爆炸或消失。但LSTM可以通过遗忘和保留记忆机制减少这些问题。”这也可以看作是在AI领域中记忆附属于认知的表现形式。“RNN隐藏状态的结构以循环形成记忆的形式工作，每一时刻的隐藏层状态取决于它的过去状态。这种结构使得RNN可以保存、记住和处理长时期的过去复杂信号。”
（3）工作记忆成为AI发展过程中制约因素之一。如记忆是智能体（intelligent agents）设计中不可或缺的因素。“推理智能体必须记住它的视觉历史中相关的片段，忽略不相关的细节，基于新的信息来更新和操作记忆，以及在后面的时间里利用这些记忆做出决策。”工作记忆是视觉推理中的限制因素之一。“在这项研究工作中，我们解决了视觉推理中的第二项限制，即关于时间和记忆的限制。”“这些随机生成的三元组能够在大量的任务序列中训练视觉推理，解决它们需要对文本的语义理解，对图像序列中每张图像的视觉认知，以及决定时变答案的工作记忆。”
尽管上述记忆分类为人工智能的发展提供了比较扎实的基础，并推进了人工智能的发展。但是一旦进入到与人类记忆最为密切的情景记忆时，这个问题就不是那么乐观。比如情景记忆（episodic memory）和自传式记忆（autobiographical memory）对于AI研究的关系完全不明确。这主要与情境记忆和自传式记忆的本质有着密切关系。“情境记忆关心的是记忆者过去的时间中独特的、具体的个人体验；语义记忆是指个人抽象的、无时间的可以与他们分享的关于世界的知识。”从心理学家的角度看，情景记忆和自传式记忆有着非常强的个体体验特性，又涉及到过去的时间性。情景记忆与自传式记忆一旦和当事人割裂开来，就失去了生命力。对于机器而言，这很难想象。毕竟在机器那里，我们所能看到的是无处不在的二元分离，精神可以独立于物质存在，体验可以独立于主体存在。
2015年AI学界围绕AI未来发展探讨了如下2个问题：（1）能否创造出人类水平的AI？（2）是否存在智能爆炸？围绕问题（1）DeepMind的研究者重点探讨了这一方向的技术可能性，如德米斯·哈斯贝斯（Demis Hassabis）、Vicarious公司的迪丽·乔治（Dileep George）和卡耐基·梅隆大学的汤姆·米契尔（Tom Mitchell）；围绕问题（2）牛津大学哲学系的尼克·博斯彻姆（Nick Bostrom）、康奈尔大学的巴特·塞尔曼（Bart Selman）以及SpaceX的埃隆·马斯克（Elon Musk）等人探讨了这一问题。这些问题的探讨均可以还原到“通用AI”这一假设之上。所谓通用人工智能（AGI）是指强AI，“能够成功执行人类能够完成的智力任务的机器智能”。在杨·立坤（Yann LeChun）看来，通用人工智能发展的最大障碍是“让机器通过观察来学习预测模型。”通用2018年，腾讯公布了三大战略，通用AI、机器人实验室和AI+医疗。这些现象表明AI的未来方向是指向通用AI。
如果把通用AI当作出发点，AI中的三种观点服务于这一出发点。在目前运算能力、海量数据与优化算法成为AI发展的基础，在此基础上形成了三种不同的观点：（1）运算主义，即AI能够学习是因为其强大运算能力；（2）数据主义，即强调AI其功能是挖掘出数据深处的相关关系（Naftali Tishby，2017;王天思，2016）；（3）算法主义，即强调AI发展基于更新、更优化的算法。这三点都是为了通用AI这个方向服务的。而通用AI意识形成自身的条件是记忆。围绕解决如何形成通用智能的问题上，形成了四条与记忆有着密切的关系不同的人工记忆模式。
（1）长短期记忆网络（Long Short-Term Memory Networks）它是由一个被嵌入到网络中的显性记忆单元组成。其功能是记住较长周期的信息。这一技术主要是被顶级跨国公司如谷歌、亚马逊和微软使用，只要勇于语言识别、智能助手和属性增强的应用。
（2）弹性权重巩固算法（Elastic Weight Consolidation Algorithm），这是从神经科学中借来的概念。用来评估联结的权重，而这些权重主要是通过早期任务的重要性来评估的。这种算法主要是用于序列学习多种游戏的。目前DeepMind公司使用着这种方法。2017年，谷歌DeepMind团队发表了一篇名为《使得神经网络中持续学习成为可能》，里面提到了一种与记忆巩固（memory consolidation）有关的算法，其目的是让机器学习、记住并能够提取信息。
（3）可微分网神经计算机（Differentiable Neural Computer）这种计算机的特点是将神经网络与记忆系统联系起来，它可以像计算机一样存储信息，还可以从例子中进行学习。
（4）连续神经网络（Progressive neural networks）主要用于迷宫学习。“学习解决复杂的连续性任务，即同时可以迁移知识，但是又不会忘掉此前学到的重要信息，依然是实现人类水平的智能中的一大难题。连续神经网络的方法代表了在这一方向上的一个尝试：它们不会忘记先验知识，并通过连接到此前学习到的特征来利用这些知识。”
但是仅仅具有通用智能是不够的，AI也只是停留在空洞的形式阶段。我们可以从两个角度预见AI发展的方向。其一是从学科角度来看，AI所依赖的重要学科之一是神经科学，而神经科学的发展方向在一定程度上决定和影响了AI发展的方向。从记忆角度看，神经科学提出记忆是信息内容的编码、存储、提取，AI在人工神经网络的方向上将循环神经网络、长短记忆网络等与记忆有关的概念引入进来，极大地促进了AI自身的发展；此外，从神经科学未来的发展方向看，神经科学下一个目标是研究同理心，说明同理心的神经机制。根据中国神经科学家蒲慕明教授的观点，神经科学会将同理心作为下一个研究目标。因此，我们可以大胆预测：AI的同理心（empathy）讨论逐渐成为一个AI的发展方向之一。这一方向将为AI实现通用智能奠定更为坚实的基础；其二是从意识构成角度看，意识到底有哪些形式构成？所以类人的AI的研究必然会延续这个方向，除了更进一步研究AI的认知之外，还有就是对于记忆、情感、意志和欲望的研究。而这一点已经开始有所苗头。而在路径二中，记忆将成为不可或缺的因素。这里的记忆不是信息的存储和提取，而是使得时间意识构成的可能性条件。对于记忆，杨立昆指出，这是预测学习中的一个关键部分，即与过去有关的部分。
从记忆角度分析已经看到AI发展可能面临的危机：记忆神经网络和灾难性遗忘。第一个危机是对记忆神经网络的冲击。正如前面所分析指出，人工智能科学家很好地利用了记忆，发展出RNN、LSTM和Nested LSTM。但是他们也遇到了一个问题，正如人工智能大师杰弗瑞·亨顿（Geoffrey Hinton，2016）提出了终极之问：将人类心智注入电脑建模的人工神经网络的可能性及其意义。终结之问就是记忆神经网络发展的危机所在，这种危机并不是技术层面的危机，而是哲学性的危机；另一制约AI的危机是灾难性遗忘。认知心理学研究表明，人类自然认知系统的遗忘并不需要完全抹除先前的信息（McCloskey,M,1989）。但是，对于机器而言，遗忘就是灾难性的，即需要抹除先前的信息，这是通用智能形成过程中的一个关键障碍。如何处理灾难性遗忘成为AI发展过程中的必须解决的重要问题。所以从这个危机中我们可以看到未来AI发展可能需要解决的问题。
这种危机在两种意义上是内在的：其一是技术发展的意义上，灾难性遗忘的技术克服以及神经网络技术的未来走向。正如我们已经看到的，神经网络是机器学习的核心，如果按照心理学的学习-记忆模式，机器学习之后必然会遭遇机器记忆的问题，此处的记忆并不是信息存储，而是与回忆问题相关的，但这似乎是技术内在的悖论；其二是哲学意义上的，对记忆与遗忘的理解脱离了人类记忆的真谛。事实上，记忆与遗忘决定着人类的行为、情感和认同，这不仅适用于人类，对于未来的后人类机器而言也是如此。确立这样的原则，可以实现有效实现对AI行为的理性约束，将AI对人类的未来威胁消除在设计阶段。
面对灾难性遗忘，学术界解决这一问题的三种方式，其一是从记忆/遗忘是信息的存储与删除角度看，AI的灾难性遗忘其实质是为后续新的内容腾出必要的物理空间。从存储容量角度看，如果存储容量有限，当存储器容量满了后，删除部分信息就变得紧迫起来。这在通常的输入-输出系统中非常常见，即从被动获得信息、程序输入等角度理解记忆，这意味着灾难性遗忘属于系统本身的内在缺陷。这种路径适应于低级的机器，忽略了高级AI的学习能力。其二是神经网络的内在特征路径，即神经网络无法进行序列性学习，即完成多种任务，所以必然会出现这种问题，其克服的方法是借助神经元固化（synaptic consolidation）的方法来解决这一问题（James Kirkpatrick，2016）。其三是先验哲学分析的结果，即人类不存在这种问题，而本质上不同于人类的机器则存在这些问题，并且这一缺陷是无法克服的。很显然，谷歌公司主要从第二种意义来理解和解决这一问题。他们首先发展了多种模式的学习理论，如深度学习（deep learning）、增强学习（reinforcement learning）和序列学习（sequences learning）等概念，这些概念有效实现了AI的行为决策和任务完成的功能，并且尝试解决了灾难性遗忘。
上述三种方式存在着各自的问题，路径一由于适应于低级非智能存储器，如USB、一般性物理存储设备，所以无法适用于具有学习能力的高级AI。路径三则是哲学分析推演的结果，其主要是哲学意义，表达一种哲学立场，并且在哲学论证上具有有效性，但是对于AI的发展未必有利。路径二非常适合AI记忆的研究，但是隐含着两个方面的问题：（1）对记忆的设定是信息巩固；（2）将遗忘看作是记忆的负面现象。但是，这在哲学上看，都是不通的。记忆并非是信息的巩固，遗忘是记忆的互补面，不是完全的负面现象。
正如前面所提到的哲学与AI领域当代交往中伦理交往是主导的形式。在这个领域的探索中，哲学家并没有满足于后果论的探讨，他们将目光指向了道德主体。在这一视野中，智能体作为道德主体是否可能的问题已经得到了诸多讨论。如段伟文教授指出人工智能体作为拟主体（2016）。从记忆哲学的角度反思人工智能的发展，也会碰到的同样的问题：智能体作为记忆或回忆主体是否可能？从科学角度看，智能体具有记忆能力没有太大的疑问。因为生物学将记忆看成是信息的编码、存储和提取，这一规定直接指向信息的发送者和接受者——生物体及其基本构成单元神经元。神经科学角度将记忆看作是神经元之间联结从而形成不同的神经回路。所以将生物学和神经科学作为其自身基础的人工智能很好地解决了这一问题。让AI具有记忆能力开始从两条路径上表现出来：（1）根据人类特定记忆神经元的标记，而在人工神经元做出标记，从而产生特定的记忆行为；（2）搭建特定的神经网络回路。未来AI的发展某种意义上来说就是搭建不同的、多元记忆神经元回路，从而展示出多样的记忆行为。所以如何构建多元的记忆神经回路是未来AI发展的动向之一。MIT的利根川进（Susumu Tonewaga）利用光遗传学展开记忆痕迹研究的成果（利根川进，2012，2013，2014，2015，2016，2017）非常重要，关于未来AI机器的社会记忆研究、记忆的抑制和激活都可以在其工作基础上进行。
但是，科学上的解答并未对上述问题给予满意的答复。哲学困惑依然存在，智能机器是否是一个主体？但是事实上，“主体”概念已经在众多讨论中被“能动者”（agent），所以，相关的问题也就转化为智能体作为能动者来说，意味着什么。这样一种方式能否解决哲学困惑还有待于检验。如果回到我们最初的问题智能体具有记忆能力是否可能？从记忆行为的本质看，记忆是关于过去对象的行为，一种明显的时间性表现出来。那么对智能体而言，是否拥有过去的时间规定性呢？答案似乎是否定的，智能体的行为更多是基于结构—功能显示出来的。它们不能感知时间，尤其是无法构建过去。如果是这样，我们会看到，尽管智能体可以存储、提取信息，但是离真正的记忆尚有距离。此外，当面对AI是否可以成为回忆主体？这个问题时，一切更加不那么确定了。事实上，亚里士多德早就切断了这条道路的希望。他在分析回忆的时候指出，人、动物都可以具有记忆，但是唯独人才拥有回忆。于是一种观点开始形成：愈返回哲学原点，我们发现答案就越让人失去希望。
这一问题的澄清最终让可以让我们重新面对亨顿的终极之问。对于亨顿来说，需要解决的问题是，如何将人类智能注入到人工智能神经网络中。这一问题的解决前提是人类的心智。还原论将智能还原到生物学构成中，“我们所谈论的心智，其实就是一个电化学体系的高度集成。”在记忆问题上，我们并没有看到这种逻辑的必然推论。随着记忆与回忆关系的澄清，我们已经看到，作为记忆主体和作为回忆主体具有完全不同的根据。随着这一观念的确立，机器具有自身的意识这一点变得更加模糊和遥不可及了。
在本文的最后，需要指出的是如何看待AI中遗忘的作用？一般情况下，人们形成了比较流行的遗忘观念，即将遗忘看作是记忆的负面现象或者失效。灾难性遗忘恰恰是在这一观念下展示出来的问题。但是，遗忘的真实含义以及在AI中的地位却没有完全被揭示出来。揭示遗忘的真实含义属于记忆研究中的问题，这有待于记忆研究的进一步深入。而遗忘在AI中的正面作用却逐渐被揭示出来。2017年希伯来大学计算机与神经科学教授梯丝柏（N·Tishby）提出了信息瓶颈（Information Bottleneck）理论，这一理论指出神经网络就像把信息挤出瓶颈口一样，只留下与一般概念最为相关的特征，去掉大量无用的噪音数据。他的最有名的观点是“学习最重要的事情实际上是遗忘。”近期的神经科学研究成果则将遗忘看作是最优化决策的必要条件。“我们论证了遗忘（1）通过减少过时信息对于记忆指导的决策的影响来提升了灵活性；（2）阻止了对于特定过去时间的过拟合（overfitting），因此提升了通用性。根据这个观点，记忆的目标不是通过时间来传递信息，而是最优化决策。因此记忆系统中短暂即逝与保持同样重要。”意识到这一点，会让我们重新看待AI决策过程中记忆与遗忘的辩证关系，但这已经超出了本文的范围。
本课题系国家社会科学基金重大项目“智能革命与人类深度科技化前景的哲学研究”（17ZDA028）；教育部重大课题攻关项目“人工智能与哲学思考研究”的阶段性成果。
